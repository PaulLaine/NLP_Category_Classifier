{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Category_Classifier using BERT\r\n",
    "\r\n",
    "As explained in the previous notebook, we will be trying to apply a different NLP method on our dataset, the BERT model.\r\n",
    "\r\n",
    "First let's install the tensorflow_hub and tf-models-official libraries where will be able to extract different functions related to the BERT pre-processing model."
   ],
   "metadata": {
    "id": "pD6kjFvz6nOo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install tensorflow_hub\r\n",
    "!pip install keras tf-models-official pydot graphviz"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 9.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.6.0)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 46.7 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 50.7 MB/s \n",
      "\u001b[?25hCollecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.1 MB 42 kB/s \n",
      "\u001b[?25hCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 39.9 MB/s \n",
      "\u001b[?25hCollecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 50.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.24)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.5)\n",
      "Collecting tensorflow-text>=2.5.0\n",
      "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 29.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.8)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 44.7 MB/s \n",
      "\u001b[?25hCollecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.4.0)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 8.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.19.5)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
      "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.34.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.53.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2018.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.7.2)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.5.30)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.62.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.39.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.12)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (5.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.12.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (0.37.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official) (1.12.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (0.4.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (4.6.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official) (3.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.3.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (0.8.9)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (2019.12.20)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.0.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.2.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.2.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (21.2.0)\n",
      "Building wheels for collected packages: py-cpuinfo, seqeval\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=d99cfba8185507cb72870d34d5c519b93110d83ab0a85b6dff24b30cb8ab12a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=6e0921762928800c0a7a584a5a8451a27c6c774f840bb49376d6fd618625d6a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built py-cpuinfo seqeval\n",
      "Installing collected packages: portalocker, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed colorama-0.4.4 opencv-python-headless-4.5.3.56 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22019,
     "status": "ok",
     "timestamp": 1630281470137,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "RfLoVhiyPRLB",
    "outputId": "d448d6f0-a9aa-45ef-9819-b5b0503b6d1c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# IMPORT\r\n",
    "\r\n",
    "import os\r\n",
    "import io\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_hub as hub\r\n",
    "\r\n",
    "from keras.utils import np_utils\r\n",
    "\r\n",
    "import official.nlp.bert.bert_models\r\n",
    "import official.nlp.bert.configs\r\n",
    "import official.nlp.bert.run_classifier\r\n",
    "import official.nlp.bert.tokenization as tokenization\r\n",
    "\r\n",
    "from official.modeling import tf_utils\r\n",
    "from official import nlp\r\n",
    "from official.nlp import bert\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
    "if gpus:\r\n",
    "  try:\r\n",
    "    # Currently, memory growth needs to be the same across GPUs\r\n",
    "    for gpu in gpus:\r\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\r\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n",
    "  except RuntimeError as e:\r\n",
    "    # Memory growth must be set before GPUs have been initialized\r\n",
    "    print(e)\r\n",
    "\r\n",
    "print(\"Version: \", tf.__version__)\r\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\r\n",
    "print(\"Hub version: \", hub.__version__)\r\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Version:  2.6.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8917,
     "status": "ok",
     "timestamp": 1630281479042,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "4MXCuqlaPUxn",
    "outputId": "7d36bb96-8674-416e-e5c8-5095d0bc3933"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from google.colab import files\r\n",
    "uploaded = files.upload()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8d6485b2-668c-470c-8e46-35f40c4d9b83\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-8d6485b2-668c-470c-8e46-35f40c4d9b83\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving flinks-data-challenge.csv to flinks-data-challenge.csv\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 105656,
     "status": "ok",
     "timestamp": 1630281584684,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "YQoIC0fySp-w",
    "outputId": "ddeb1caf-8cd5-45d7-d828-7e6ee6dde7c5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(io.StringIO(uploaded['flinks-data-challenge.csv'].decode('utf-8')))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1057,
     "status": "ok",
     "timestamp": 1630281585734,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "5qqwwoFHSHc8",
    "outputId": "37e35bb3-b538-42d6-a89e-3e5218dbeff3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>goal</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>launched</th>\n",
       "      <th>deadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>1000</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>2015-10-09 11:36:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>45000</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>2013-02-26 00:20:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>5000</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>2012-04-16 04:24:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Community Film Project: The Art of Neighborhoo...</td>\n",
       "      <td>19500</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>2015-07-04 08:35:03</td>\n",
       "      <td>2015-08-29 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>50000</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>2016-02-26 13:38:27</td>\n",
       "      <td>2016-04-01 13:38:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...             deadline\n",
       "0           0  ...  2015-10-09 11:36:00\n",
       "1           1  ...  2013-02-26 00:20:50\n",
       "2           2  ...  2012-04-16 04:24:11\n",
       "3           3  ...  2015-08-29 01:00:00\n",
       "4           4  ...  2016-04-01 13:38:27\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1630281585736,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "k_LBQNhbQ8y0",
    "outputId": "77dd1da3-9588-4a10-e6bc-689885335576"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this model, only the name project is important and we want to make sure to have a balanced dataset so we are applying the same cleaning functions that we used in the previous notebook :"
   ],
   "metadata": {
    "id": "_KaiNsEp84zr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def balance_datas(x):\r\n",
    "    frames = []\r\n",
    "    for category in x[\"main_category\"].unique():\r\n",
    "        df_test = x[x[\"main_category\"] == category].sample(3000)\r\n",
    "        frames.append(df_test)\r\n",
    "    df_balanced = pd.concat(frames)\r\n",
    "    return df_balanced\r\n",
    "    \r\n",
    "    \r\n",
    "def cleaning_df(x):\r\n",
    "  #Remove index column\r\n",
    "  df_clean = x.iloc[:, 1:]\r\n",
    "\r\n",
    "  #Sort by main_category\r\n",
    "  df_clean = df_clean.sort_values(by=\"main_category\")\r\n",
    "\r\n",
    "  #Drop row with missing values\r\n",
    "  df_clean = df_clean.dropna()\r\n",
    "\r\n",
    "  #Balanced datas to have 3000 row for each category\r\n",
    "  df_clean = balance_datas(df_clean)\r\n",
    "\r\n",
    "  # Clean index and remove inconsistant features\r\n",
    "  df_clean = df_clean.reset_index()\r\n",
    "  df_clean = df_clean.drop(['index', 'goal', 'sub_category', 'launched', 'deadline'], axis = 1)\r\n",
    "\r\n",
    "  return df_clean\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "HtDckAA7TIPu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_bert = cleaning_df(df)\r\n",
    "df_bert.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>main_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8 Little Zombies - a hardcover children's book</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Up the Witchpunx Zine Project</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Story-Eaters Traveling Puppet Show</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Seduction of Etain (poetry and art)</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reclaiming Vintage Hankies</td>\n",
       "      <td>Art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name main_category\n",
       "0  8 Little Zombies - a hardcover children's book           Art\n",
       "1                   Up the Witchpunx Zine Project           Art\n",
       "2          The Story-Eaters Traveling Puppet Show           Art\n",
       "3         The Seduction of Etain (poetry and art)           Art\n",
       "4                      Reclaiming Vintage Hankies           Art"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1630281586782,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "PTJfn5rFT-jn",
    "outputId": "187941f2-f001-48d1-b498-9b98c5ea7062"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We than split our data into 80% train and 20% test"
   ],
   "metadata": {
    "id": "bx5U_pqb98nG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x = df_bert.name.values\r\n",
    "y = df_bert.main_category.values\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=32)"
   ],
   "outputs": [],
   "metadata": {
    "id": "YTAHteuVW53g"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To optimize our labelization, we are then converting our main_category into one-hot encoding values."
   ],
   "metadata": {
    "id": "_8IBXBKA-YKK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "encoder = LabelEncoder()\r\n",
    "encoder.fit(y)\r\n",
    "encoded_Y_test = encoder.transform(y_test)\r\n",
    "encoded_Y_train = encoder.transform(y_train)\r\n",
    "\r\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\r\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\r\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)"
   ],
   "outputs": [],
   "metadata": {
    "id": "5O4FjShfauRr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization\n",
    "\n",
    "To tokenize our text we will use some functions from official.nlp.bert package and the pretrained [BERT](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270) model itself. \\\\\n",
    "First we get the BERT model. "
   ],
   "metadata": {
    "id": "-1t2poiEbYfg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",\r\n",
    "                            trainable=True)"
   ],
   "outputs": [],
   "metadata": {
    "id": "tWFpe7OObTX4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\r\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\r\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ],
   "outputs": [],
   "metadata": {
    "id": "5_HuDPCBbaw6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that in above cell we have loaded some variables using the bert_layer we have downloaded. \n",
    "\n",
    "1.   ```vocab_file``` reads the vocab file associated to the downloaded model.\n",
    "2.   ```do_lower_case``` reads binary variable which if ```True``` means tokenizer will reformat all text to lower case rendering model to be not case sensitive. Should be ```False``` by default. You can check in a cell below.\n",
    "3.   ```tokenizer``` builds tokenizer using variables 1 and 2.\n",
    "\n",
    "Lastly we need to add two additional tokens: Classification and Seperation. We will add these through functions we will use to tokenize our text."
   ],
   "metadata": {
    "id": "EsDLPc5L-_n0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[101, 102]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1630281605332,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "z-MPnAd9b4zR",
    "outputId": "3916b21c-7e97-4b86-915b-3add04dc6cec"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By this point we have everything for tokenization. This will take a bit as we have quite a bit of data."
   ],
   "metadata": {
    "id": "atPe78U7_Iqk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def encode_names(n):\r\n",
    "   tokens = list(tokenizer.tokenize(n))\r\n",
    "   tokens.append('[SEP]')  # seperation token. Would bemuch more useful if you had a multiple text input.\r\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\r\n",
    "\r\n",
    "name = tf.ragged.constant([\r\n",
    "    encode_names(n) for n in x_train])"
   ],
   "outputs": [],
   "metadata": {
    "id": "KP-Iu1Nkb6Gv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('Tokenized Names shape', name.shape.as_list())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tokenized Names shape [36000, None]\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1630281611186,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "LheMCi4-b9-H",
    "outputId": "090ab386-6e70-48bf-8c83-ae94e0275eac"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "name[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([12685, 34850, 15835, 11162,   102], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1630281611186,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "yzN1hHaecB6O",
    "outputId": "5ce2f562-c08c-4e58-d4fc-d591923d3bdf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have an example on how the tokenizer is \"tokenizing\" our datas"
   ],
   "metadata": {
    "id": "boGDp75fAOQE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Topography Dance Film'"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 125,
     "status": "ok",
     "timestamp": 1630281611298,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "zsJWjZTqcE7L",
    "outputId": "990208f4-b28f-495d-bc8f-8d86966d6880"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tokenizedName = tokenizer.tokenize(x_train[0])\r\n",
    "for i in tokenizedName:\r\n",
    "  print(i, tokenizer.convert_tokens_to_ids([i]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top [12685]\n",
      "##ography [34850]\n",
      "Dance [15835]\n",
      "Film [11162]\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1630281611299,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "cTkjVWdEcGtc",
    "outputId": "dfbed440-eb5f-4b51-9a2e-b908f88eb2f0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*name.shape[0]\r\n",
    "input_word_ids = tf.concat([cls, name], axis=-1)\r\n",
    "_ = plt.pcolormesh(input_word_ids[0:10].to_tensor())"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1630281611764,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "zp_BNeqLcLze",
    "outputId": "35a2c6b5-8071-4bc7-c172-609b85c69a95"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What you see above is a graphical representation of our tokenized name project. First token is our classification token. Other colored blocks than background are other tokens. The end background is simply padding.\n",
    "\n",
    "## Masked and Input Types\n",
    "\n",
    "The model expects two additional inputs:\n",
    "\n",
    "* The input mask\n",
    "* The input type\n",
    "\n",
    "The mask allows the model to cleanly differentiate between the content and the padding. The mask has the same shape as the `input_word_ids`, and contains a `1` anywhere the `input_word_ids` is not padding."
   ],
   "metadata": {
    "id": "owkmGdpHCaJv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_mask = tf.ones_like(input_word_ids).to_tensor()\r\n",
    "\r\n",
    "plt.pcolormesh(input_mask)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f0958dee790>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 2112,
     "status": "ok",
     "timestamp": 1630281613874,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "sIHlF39UCprt",
    "outputId": "d49f742b-ac8e-4bae-a1e1-2ce79b8f893f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here each yellow block has some input. We just make this for the model to differ between padding and input."
   ],
   "metadata": {
    "id": "IhQ-0-vpCwMb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "type_cls = tf.zeros_like(cls)\r\n",
    "type_name = tf.ones_like(name)\r\n",
    "input_type_ids = tf.concat([type_cls, type_name], axis=-1).to_tensor()\r\n",
    "\r\n",
    "plt.pcolormesh(input_type_ids)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f0954a8f050>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 2142,
     "status": "ok",
     "timestamp": 1630281648076,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "4yRsD_C_CtAR",
    "outputId": "e7b483b3-78b2-4fe2-fa75-815ce50b7b3a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's hard to see but we added an empty block in front of each tweet for the `[CLS]` token. Check tensor below"
   ],
   "metadata": {
    "id": "g7006Cs9C2Jr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remake into a function for normal use\n",
    "\n",
    "So at this point we have all of our three inputs:\n",
    "\n",
    "1.   Tokens\n",
    "2.   Input mask\n",
    "3.   Input type\n",
    "\n",
    "It will make our work easier both now and in the future if we remake everything into functions.\n",
    "\n",
    "First we check the length of each name project to get the max one"
   ],
   "metadata": {
    "id": "sENxnbTGck2k"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lens = [len(i) for i in input_word_ids]"
   ],
   "outputs": [],
   "metadata": {
    "id": "B2vY0tNkcZHX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_seq_length = max(lens)\r\n",
    "print('Max length is:', max_seq_length)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max length is: 50\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1630281742012,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "o5usarbRct8S",
    "outputId": "fa592689-d852-4fe1-b4df-5cc4459d701a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To secure our model with eventually longer name in our test dataset or for more new name we rise the max value."
   ],
   "metadata": {
    "id": "o1Ip7YjkFq97"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_seq_length = int(1.5*max_seq_length)\r\n",
    "print('Max length is:', max_seq_length)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max length is: 75\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1630281742149,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "HWVzUAQedF1x",
    "outputId": "3b78d979-8c79-4c0b-c642-6e131e08e6dc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def encode_names(n, tokenizer):\r\n",
    "   tokens = list(tokenizer.tokenize(n))\r\n",
    "   tokens.append('[SEP]')\r\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)\r\n",
    "\r\n",
    "def bert_encode(string_list, tokenizer, max_seq_length):\r\n",
    "  num_examples = len(string_list)\r\n",
    "  \r\n",
    "  string_tokens = tf.ragged.constant([\r\n",
    "      encode_names(n, tokenizer) for n in np.array(string_list)])\r\n",
    "\r\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\r\n",
    "  input_word_ids = tf.concat([cls, string_tokens], axis=-1)\r\n",
    "\r\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\r\n",
    "\r\n",
    "  type_cls = tf.zeros_like(cls)\r\n",
    "  type_tokens = tf.ones_like(string_tokens)\r\n",
    "  input_type_ids = tf.concat(\r\n",
    "      [type_cls, type_tokens], axis=-1).to_tensor(shape=(None, max_seq_length))\r\n",
    "\r\n",
    "  inputs = {\r\n",
    "      'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\r\n",
    "      'input_mask': input_mask,\r\n",
    "      'input_type_ids': input_type_ids}\r\n",
    "\r\n",
    "  return inputs"
   ],
   "outputs": [],
   "metadata": {
    "id": "vz89rjz0dDbk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And now we preprocess inputs."
   ],
   "metadata": {
    "id": "46w5tn0MGBEV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train = bert_encode(x_train, tokenizer, max_seq_length)\r\n",
    "X_test = bert_encode(x_test, tokenizer, max_seq_length)"
   ],
   "outputs": [],
   "metadata": {
    "id": "6Q0fykVcdHzR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MODEL \n",
    "\n",
    "### Training\n",
    "\n",
    "We need to set up our model using the inputs we made, BERT model that we downloaded and an output layer based on num of classes we are using."
   ],
   "metadata": {
    "id": "3HYiOL59dQP5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "num_class = len(encoder.classes_)  # Based on available class selection\r\n",
    "max_seq_length = max_seq_length  \r\n",
    "\r\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n",
    "                                       name=\"input_word_ids\")\r\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n",
    "                                   name=\"input_mask\")\r\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n",
    "                                    name=\"segment_ids\")\r\n",
    "\r\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])                                  \r\n",
    "\r\n",
    "output = tf.keras.layers.Dropout(rate=0.3)(pooled_output)\r\n",
    "\r\n",
    "output = tf.keras.layers.Dense(num_class, activation='softmax', name='output')(output)\r\n",
    "\r\n",
    "model = tf.keras.Model(\r\n",
    "    inputs={\r\n",
    "        'input_word_ids': input_word_ids,\r\n",
    "        'input_mask': input_mask,\r\n",
    "        'input_type_ids': segment_ids\r\n",
    "        },\r\n",
    "        outputs=output)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7fa250864665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Based on available class selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n\u001b[1;32m      5\u001b[0m                                        name=\"input_word_ids\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "executionInfo": {
     "elapsed": 161,
     "status": "error",
     "timestamp": 1630331786548,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "1t-17TJ0dKur",
    "outputId": "2c5481ed-9fc7-4b37-eadf-ed9b53c5c847"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the training parameters."
   ],
   "metadata": {
    "id": "Ks6SmPyNGLNN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = 3\r\n",
    "batch_size = 64  # selected based on our GPU resources\r\n",
    "eval_batch_size = batch_size\r\n",
    "\r\n",
    "train_data_size = len(dummy_y_train)\r\n",
    "steps_per_epoch = int(train_data_size / batch_size)\r\n",
    "num_train_steps = steps_per_epoch * epochs\r\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\r\n",
    "\r\n",
    "optimizer = nlp.optimization.create_optimizer(\r\n",
    "    2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ],
   "outputs": [],
   "metadata": {
    "id": "BFA9p1N-dVMM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(optimizer=optimizer,\r\n",
    "              loss='categorical_crossentropy',\r\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {
    "id": "nfUXwyPwdY6H"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 75)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 177853441   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           keras_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 15)           11535       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 177,864,976\n",
      "Trainable params: 177,864,975\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1630281749989,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "4f9wCGnVdaoo",
    "outputId": "ee212088-177d-4796-c92b-6cdd0f965488"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history = model.fit(X_train,\r\n",
    "                    dummy_y_train,\r\n",
    "                    epochs=epochs,\r\n",
    "                    batch_size=batch_size,\r\n",
    "                    validation_data=(X_test, dummy_y_test),\r\n",
    "                    verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "563/563 [==============================] - 1158s 2s/step - loss: 1.8725 - accuracy: 0.4005 - val_loss: 1.4711 - val_accuracy: 0.5340\n",
      "Epoch 2/3\n",
      "563/563 [==============================] - 1133s 2s/step - loss: 1.3935 - accuracy: 0.5577 - val_loss: 1.4093 - val_accuracy: 0.5569\n",
      "Epoch 3/3\n",
      "563/563 [==============================] - 1129s 2s/step - loss: 1.2358 - accuracy: 0.6092 - val_loss: 1.4151 - val_accuracy: 0.5586\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3420760,
     "status": "ok",
     "timestamp": 1630285170860,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "GESzPgTmdcGv",
    "outputId": "b5fc26a4-2d91-4836-ed88-c704c9a08c2a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss, accuracy = model.evaluate(X_train, dummy_y_train, verbose=False)\r\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\r\n",
    "loss, accuracy = model.evaluate(X_test, dummy_y_test, verbose=False)\r\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Accuracy: 0.6570\n",
      "Testing Accuracy:  0.5586\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454986,
     "status": "ok",
     "timestamp": 1630285625837,
     "user": {
      "displayName": "Paul",
      "photoUrl": "",
      "userId": "14267296694645581633"
     },
     "user_tz": 240
    },
    "id": "DaPlba_qdg_u",
    "outputId": "2aa7305b-83f4-4f50-af54-d02783c0dcc4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the BERT model improve our previous classification accuracy from 52% to 56%\n",
    "\n",
    "However, the training and testing accuracy score is still generaly low. \n",
    "\n",
    "But the fact that the 2 results are close to each other make me again think that one of the problems here may be the construction of the dataset and the way the project names are assigned among all the different categories.\n",
    "Indeed, I think some categories are too related to others, which can create confusion when we need to assign a project to a category. \n",
    "\n",
    "A next challenge could be to find the most correlated categories and create more general categories to simplify the first part of our classification, and then we could implement more specific models that could classify each project into their more specific category."
   ],
   "metadata": {
    "id": "RqJKk1mDRCAT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion \r\n",
    "\r\n",
    "This challenge was very interested to work on. I was a little bit confused and frustrated by the fact that I coulnd't find a good solution for this problem even with some advanced methods like BERT but i think that an interesting axe of reflexion for this challenge could be to work more on the data rather than focus on the modeling part.\r\n",
    "\r\n",
    "In any case, I hope you found my work interesting, thank you for reading it !"
   ],
   "metadata": {
    "id": "h5eyLnB0OFMQ"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4/o8IqJGf+nxoFG4uDf0C",
   "collapsed_sections": [],
   "name": "Flinks_challenge_BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}